     1	FTP'd from cert.org:
     2	File pub/virus-l/docs/net.hormones
     3	
     4	Date: Thu, 16 Mar 89 20:56:18 +0100
     5	From: David Stodolsky <stodol@diku.dk>
     6	
     7	Net Hormones: Part 1 - 
     8	Infection Control assuming Cooperation among Computers
     9	
    10	Copyright (c) 1989 David S. Stodolsky, PhD. All rights reserved.
    11	
    12	1.   Abstract
    13	
    14	A new type of infection control mechanism based upon contact tracing is 
    15	introduced. Detection of an infectious agent triggers an alerting 
    16	response that propagates through an affected network. A result of the 
    17	alert is containment of the infectious agent as all hosts at risk 
    18	respond automatically to restrict further transmission of the agent. 
    19	Individually specified diagnostic and treatment methods are then 
    20	activated to identify and destroy the infective agent. The title "Net 
    21	Hormones" was chosen to indicate the systemic nature of this programmed 
    22	response to infection.
    23	
    24	2.   Introduction
    25	
    26	A new type of infection control mechanism that is based upon network-
    27	wide communication and that depends upon cooperation among computer 
    28	systems is presented. Neither diagnosis nor treatment is necessary for 
    29	the operation of the mechanism. The mechanism can automatically trigger 
    30	responses leading to effective containment of an infection. The 
    31	identification and destruction of the infectious agent is determined by 
    32	individual actions or programs. This permits a highly desirable 
    33	heterogeneity in diagnostic and treatment methods.
    34	
    35	Definition: "Hormone . . . 1: a product of living cells that circulate 
    36	in body fluids or sap and produces a specific effect on the activity of 
    37	cells remote from its point of origin; especially one exerting a 
    38	stimulatory effect on a cellular activity. 2: a synthetic substance 
    39	that acts like a hormone (Webster's new collegiate dictionary, 1976)." 
    40	The analogy here is between each network node or computer system and 
    41	the cell. In biological systems hormones attach to specialized 
    42	receptors on the cell surface resulting in cell activation. In the 
    43	system described here, a match between a code in a system archive and a 
    44	code delivered as part of an alerting message results in activation. 
    45	Alerting messages circulated electronically serve the role of hormones. 
    46	
    47	Epidemiology has traditionally had three major approaches to the 
    48	control of infectious agents:
    49	
    50	:1 - Treatment of the sick (e. g., penicillin)
    51	
    52	:2 - Contact tracing (e. g., social-work notification programs, laws 
    53	forcing the reporting of certain diseases and of contacts of infected 
    54	persons)
    55	
    56	:3 - Prevention (e. g., vaccination, public information campaigns)
    57	
    58	In computer system terms:
    59	
    60	:1 - Treatment of infections (e. g., various programs and manually 
    61	installed patches and fixes)
    62	
    63	:2 - Contact tracing (e. g., software "recall", and other manual 
    64	operations)
    65	
    66	:3 - Prevention (e. g., various programs for blocking virus 
    67	replication, alerting users, and for logging suspicious events)
    68	
    69	Contact tracing has been neglected with computer systems, although it 
    70	could be argued it is much easier with computer systems than with 
    71	biological systems. Currently such tracing depends upon people reading 
    72	reports and determining if their system is subject to infection, 
    73	performing diagnostic tests, determining a treatment method, obtaining 
    74	software, and so on. This is chancy and time consuming, requiring most 
    75	often people with the highest level of expertise. As computers and 
    76	networks speed up, an infectious agent could spread through a network 
    77	in hours or minutes. "Once a virus has infected a large number of 
    78	computers on a network, the number of infected removable media elements 
    79	will begin to skyrocket. Eventually, if the virus continues to go 
    80	undetected, a stage is reached in which the probability of identifying 
    81	and recovering all of the infected media is virtually zero (McAfee, 
    82	1989)." An automated contact tracing system thus seems essential in the 
    83	future if infectious agents are to be controlled.
    84	
    85	3.   Threats
    86	
    87	"The modification of an existing virus to incorporate a long term delay
    88	(such as 6 months or even a year) coupled with a totally destructive
    89	manipulation task (such as a FAT, Boot sector scribble followed by a
    90	complete format) is a fairly simple task. Such an action would convert
    91	even a crude virus strain such as the Lehigh 1 virus into a
    92	devistating (sic) strain. (Eg the comment by Ken that the modified 
    93	version of the Lehigh virus is now far more dangerous due to 
    94	modification of the delay in activation of its manipulation task) 
    95	(Ferbrache, 1989)."
    96	
    97	Scott (1989) requested comments on:
    98	 
    99	"A little future speculation here... currently we seem to be fighting a
   100	losing battle against virus detection and as viruses improve it's
   101	unlikely that that will change.  If we want the capability to download
   102	shareware, etc, from bulletin boards, etc, then we must assume that we
   103	cannot check the software for a virus with 100% success before running
   104	it.  In general, you can't know the output of a program given the
   105	input without running it, except in special cases.
   106	 
   107	We can check for *known* viruses; but how long before shape-changing
   108	and mutating viruses hit the scene that defeat all practical
   109	recognition techniques?"
   110	
   111	An inapparent infection could spread rapidly, with damage noted only 
   112	much later. Consider a worm that is constructed to carry a virus. The 
   113	worm infects a system, installs the virus and then infects other nearby 
   114	systems on the net. Finally, it terminates erasing evidence of its 
   115	existence on the first system. The virus is also inapparent, it waits 
   116	for the right moment writes some bits and then terminates destroying 
   117	evidence of its existence. Later the worm retraces its path reads some 
   118	bits, then writes some bits and exits. The point is that an inapparent 
   119	infection could spread quite widely before it was noticed. It also 
   120	might be so hard to determine whether a system was infected or not, 
   121	that it would not be done until damage was either immanent or apparent. 
   122	This analysis suggests response to network-wide problems would best be 
   123	on a network level. 
   124	
   125	4.   Theory of operation
   126	
   127	Computers generate (in the simplest case) random numbers which are used 
   128	to label transactions. A transaction is defined as an interaction 
   129	capable of transmitting an infectious agent. After each transaction 
   130	both systems therefore have a unique label or code for that 
   131	transaction. In the event that a system is identified as infected, the 
   132	transaction codes which could represent transactions during which the 
   133	agent was transmitted are broadcast to all other computers. If a 
   134	receiving computer has a matching code, then that system is alerted to 
   135	the possibility of the agent's presence, and can broadcast transaction 
   136	codes accumulated after the suspect contact. This iterates the process, 
   137	thus identifying all carriers eventually. The effect is to model the 
   138	epidemiological process, thereby identifying all carriers through 
   139	forward and backward transaction tracking (Stodolsky, 1979a; 1979b; 
   140	1979c; 1983; 1986). 
   141	
   142	5.   The process of infection control
   143	
   144	The process can be broken down into routine and alerting operations. 
   145	During routine operations, each file transfer is labeled in a way that 
   146	does not identify the systems involved. These labels are time stamped 
   147	(or have time stamps encoded in them). They are written into archives 
   148	on each system, ideally write-once/read-many times devices or some 
   149	other type of storage that could not easily be altered. 
   150	
   151	Alerting procedures are invoked when an infectious agent is noted or 
   152	when a suspect transaction code is received that matches one in the 
   153	system's archive. The earliest time the agent could have arrived at the 
   154	system and latest time (usually the moment the agent is noted or a 
   155	received suspect transaction code is matched) it could have been 
   156	transmitted from the system are used to delimit suspect transaction 
   157	codes. These codes are broadcast to alert other systems to the 
   158	potential presence of the agent.
   159	
   160	In the simplest and most common case, if a system gets an alert that 
   161	indicates, "You could have been infected at time one," then the system 
   162	automatically packages the transaction codes between time one and the 
   163	present time to generate a new alert indicating the same thing to other 
   164	systems with which it has had contact. 
   165	
   166	Another automatic response could be to immediately cut off 
   167	communications in progress, thus reducing the risk of infection. A 
   168	further benefit of such a reaction would be the possibility of 
   169	disrupting the transfer of an infectious agent. Such a disrupted agent 
   170	would be harmless and easily identified and evaluated. Reestablishment 
   171	of communication could occur immediately with new procedures in force 
   172	that could warn new users that an alert was in progress as well as 
   173	limiting the type of transfers that could take place.
   174	
   175	5.1.   Practical considerations
   176	
   177	Direct identification, as opposed to identification through forward 
   178	tracing notification, does not delimit effectively the earliest time 
   179	that an agent could have been present on a system. Thus an alert from 
   180	an originating system could include all transaction codes written prior 
   181	to the identification (or some default value). This could generate 
   182	excessive reaction on the network. This reaction could be controlled if 
   183	another system in a later alert indicated it had originated the 
   184	infection on the system originating the alert. Thus, protection of 
   185	identity which reduces any inhibition about reporting infection is 
   186	important. The type of reaction discussed here might be called a panic 
   187	reaction, because an excessive number of systems might be notified of 
   188	potential infection in the first instance. 
   189	
   190	A more restricted response could be generated if persons at the alert 
   191	originating system analyzed the causative agent, thereby hopefully 
   192	establishing the earliest time the agent could have been present on 
   193	that system. In this case, the suspect transactions could be delimited 
   194	effectively and all systems that could have been infected would be 
   195	notified, as would the system that had transmitted the agent to the 
   196	system originating the alert (assuming one exists). Ideally, each 
   197	notified system would be able to determine if it had received or 
   198	originated the infection and respond accordingly. 
   199	
   200	5.2.   Forward tracing assumption
   201	
   202	Assume, however, that rapid response is desired. Each notified system 
   203	would then react as if it had been notified of an infection transmitted 
   204	to it. It would package the transaction codes that had been written 
   205	later than the suspect transaction code it had received and issue a 
   206	secondary alert. This forward tracing assumption would lead to quite 
   207	effective control because of the exponential growth in the number of 
   208	infected hosts in epidemics (and exponential growth of alerts resulting 
   209	>From forward tracing). That is, a system can infect many others as a 
   210	result of a single infective agent transmitted to it. Forward tracing 
   211	would alert all systems that the alerting system could have infected. 
   212	These newly alerted systems would also issue forward trace alerts, and 
   213	this would continue until containment was reached under the forward 
   214	tracing assumption.
   215	
   216	5.3.   Backward tracing of suspect contacts and diagnosis
   217	
   218	As a result of this rapid forward tracing response, it is likely that 
   219	more active infections would be identified. The resulting new 
   220	information could be used to more effectively characterize the life 
   221	cycle of the agent, thereby hopefully permitting effectively delimited 
   222	backward tracing. Also as a result of accumulated information, positive 
   223	tests for the agent would become available. Once this stage had been 
   224	reached the focus of action could shift from control of suspect 
   225	transactions to control of transactions known to facilitate the 
   226	transmission of the agent.
   227	
   228	6.   Feasibility and Efficiency
   229	
   230	Both technical and social factors play a key role in the operation of 
   231	the control mechanism. Contact tracing is probably most effective for 
   232	sparsely interacting hosts. The rate of transfer of the infectious 
   233	agent as compared to the rate of transfer of the suspect transaction 
   234	codes is also a critical factor. Recording of transactions can be 
   235	comprehensive on computer networks, however, unregistered transactions 
   236	will be a factor in most cases. Once the infectious agent has been 
   237	identified, the type of transactions capable of transmitting the agent 
   238	can be delimited. This could increase efficiency. 
   239	
   240	6.1.   Social organization of alerts
   241	
   242	Another major efficiency factor is errors in origination of alerts. 
   243	Since protected messages would trigger network-wide alerts, it is 
   244	important that false alarms are controlled effectively. On the other 
   245	hand, failure to report an infection could permit an infectious agent 
   246	to spread in an uncontrolled manner and could increase the number of 
   247	systems unnecessarily alerted. Successful operation of the mechanism 
   248	described above assumes voluntary cooperation among affected systems. 
   249	This assumption could be relaxed by application of an enforcement 
   250	mechanism. It would require substantially greater complexity and 
   251	greater centralization of coordination. In other words, if cooperation 
   252	was not forthcoming "voluntarily", users would likely be treated to a 
   253	complicated, restrictive, and resource intensive mechanism that would 
   254	be developed to enforce it. "Estimates of the damages inflicted by 
   255	November's Internet infection alone ranged upward of $100 million . . . 
   256	(McAfee, 1989)." Costs of this magnitude make it very likely that even 
   257	expensive enforcement mechanisms will be developed if they are made 
   258	necessary.
   259	
   260	The simplest organizational strategy would assume that protection of 
   261	identity was not needed, but this would also be likely to inhibit 
   262	alerting. True anonymity, however, permits irresponsible behavior to go 
   263	unchecked. A reputation preserving anonymity (pseudonymity) would be 
   264	desirable to ensure both protection and accountability and thereby 
   265	promote cooperation. Pseudonyms would best be the property of persons 
   266	(in association with a computer system). 
   267	
   268	Even sincere cooperation, however, would not eliminate inefficiencies 
   269	resulting from false alarms or failure to alert. Both inadequate 
   270	training and poor judgement are likely sources of these errors. If 
   271	users realize that there are reputational costs associated with these 
   272	failures, then they are likely to be motivated to minimize them. False 
   273	alarms are already a major problem because of user inexperience and the 
   274	high level of defects in widely used software. A reputational mechanism 
   275	would motivate increased user education and more careful software 
   276	selection, with a corresponding pressure on software publishers to 
   277	produce well behaved and carefully documented products. 
   278	
   279	6.2.   Enforcing cooperation
   280	
   281	Crypto-protocols could be used to ensure that a non-cooperator could 
   282	not communicate freely with others using the infection control 
   283	mechanism. This type of communication limiting could be used routinely 
   284	to ensure that a system requesting connection was not infected. In 
   285	effect, systems would exchange health certificates before file 
   286	exchanges, to ensure that they would not be infected. A system that 
   287	could not show a health certificate could be rejected as a conversation 
   288	partner due to risk of infection. This would no doubt enforce 
   289	cooperation. The mechanism (Stodolsky, 1986) is beyond the scope of 
   290	this note.
   291	
   292	6.3.   Non-network transfers
   293	
   294	While the discussion above has focused on transfers through networks, 
   295	the same principles could be applied to disk or tape transfers. The 
   296	originating system would write a transaction code on the medium with 
   297	each file. Protection of identity would possibly be reduced under this 
   298	type of transfer. Since there is no question about the directionality 
   299	of transmission of an infectious agent in off-line transfers, non-
   300	network transmission is likely to be easier to control. Several other 
   301	factors, such as the rate of spread of the agent, are likely to make 
   302	such infections less troublesome. 
   303	
   304	7.   Summary and Benefits 
   305	
   306	The idea behind Net Hormones is to make immanent danger apparent. More 
   307	precisely Net Hormones permit the visualization of infection risk. 
   308	
   309	7.1.   Control of unidentified infectious agents.
   310	
   311	Net Hormones work by permitting isolation of infectious hosts from 
   312	those at risk. Identification of the infectious agent is not required 
   313	for action. Therefore, new and as yet unidentified agents can be 
   314	effectively controlled.
   315	
   316	7.2.   Rapid response
   317	
   318	Hosts could automatically respond to alerts by determining if they had 
   319	been involved in suspect contacts, and generate new alerts that would 
   320	propagate along the potential route of infection. 
   321	 
   322	7.3.   Protection of identity
   323	
   324	The mechanism could function without releasing the identity of an 
   325	infected host. This could be crucial in the case an institution that 
   326	did not wish it to be publicly know that its security system had been 
   327	compromised, or in the case of use of unregistered software. More 
   328	precisely, software obtain by untraceable and anonymous file transfers 
   329	could be protected by this mechanism without release of users' 
   330	identity.
   331	
   332	7.4.   Distributed operation
   333	
   334	Operation is not dependent upon a centralized register or enforcement 
   335	mechanism. Some standardization would be helpful, however, and a way to 
   336	broadcast alerts to all potential hosts would be valuable.
   337	
   338	8.   References
   339	
   340	Ferbrache, David J. (1989, February 10). Wide area network worms. 
   341	VIRUS-L Digest, V. 2 : Issue 44. [<davidf@CS.HW.AC.UK> <Fri, 10 Feb 89 
   342	11:45:37 GMT>]
   343	
   344	McAfee, J. D. (1989, February 13). In depth: Managing the virus threat. 
   345	Computerworld, 89-91; 94-96.
   346	
   347	Scott, Peter. (1989, February 10). Virus detection. VIRUS-L Digest, V. 
   348	2 : Issue 44. [PJS%naif.JPL.NASA.GOV@Hamlet.Bitnet 
   349	<pjs@grouch.jpl.nasa.gov>. <Fri, 10 Feb 89 10:46:21 PST>]
   350	
   351	Stodolsky, D. (1979a, April 9). Personal computers for supporting 
   352	health behaviors. Stanford, CA: Department of Psychology, Stanford 
   353	University.  (Preliminary proposal)
   354	
   355	Stodolsky, D. (1979b, May 21). Social facilitation supporting health 
   356	behaviors. Stanford, CA: Department of Psychology, Stanford University. 
   357	(Preliminary proposal)
   358	
   359	Stodolsky, D. (1979c, October). Systems approach to the epidemiology 
   360	and control of sexually transmitted diseases. Louisville, KY: System 
   361	Science Institute, University of Louisville. (Preliminary project 
   362	proposal)
   363	
   364	Stodolsky, D. (1983, June 15). Health promotion with an advanced 
   365	information system. Presented at the Lake Tahoe Life Extension 
   366	Conference. (Summary)
   367	
   368	Stodolsky, D. (1986, June). Data security and the control of infectious 
   369	agents. (Abstracts of the cross disciplinary symposium at the 
   370	University of Linkoeping, Sweden: Department of Communication Studies). 
   371	
   372	Webster's new collegiate dictionary. (1976). Springfield, MA: G. & C. 
   373	Merriam
   374	
   375	-------------------------------------------------------------
   376	
   377	David Stodolsky                          diku.dk!stodol@uunet.UU.NET
   378	Department of Psychology                       Voice + 45 1 58 48 86
   379	Copenhagen Univ., Njalsg. 88                    Fax. + 45 1 54 32 11
   380	DK-2300 Copenhagen S, Denmark                         stodol@DIKU.DK
